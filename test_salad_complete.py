#!/usr/bin/env python3
"""
Complete test of Salad transcription with all enhanced features and Google Drive upload
"""

import os
import sys
import json
import logging
from pathlib import Path
from datetime import datetime

sys.path.insert(0, '/var/www/call-recording-system')

from dotenv import load_dotenv
from src.transcription.salad_transcriber_enhanced import SaladTranscriberEnhanced
from src.storage.google_drive import GoogleDriveManager
from src.storage.structured_data_organizer import StructuredDataOrganizer
from src.database.session import SessionManager
from src.database.models import CallRecording

# Load environment
load_dotenv('/var/www/call-recording-system/.env')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_single_recording(recording_file: str):
    """Test a single recording through the entire pipeline"""

    logger.info("=" * 80)
    logger.info(f"TESTING RECORDING: {recording_file}")
    logger.info("=" * 80)

    # Initialize components
    logger.info("\n1. Initializing components...")

    # Transcriber with ALL features enabled
    transcriber = SaladTranscriberEnhanced(
        api_key=os.getenv('SALAD_API_KEY'),
        organization_name=os.getenv('SALAD_ORGANIZATION_NAME'),
        engine='full',
        language='en-US',
        initial_prompt="This is a business phone call. Include proper names, companies, and technical terms.",
        enable_monitoring=True,
        enable_diarization=True,  # Enable speaker identification
        enable_summarization=True,  # Enable summarization
        custom_vocabulary="Exavault RingCentral Salad transcription API webhook"
    )

    # Data organizer
    organizer = StructuredDataOrganizer()

    # Google Drive manager
    drive_manager = GoogleDriveManager(
        credentials_path=os.getenv('GOOGLE_CREDENTIALS_PATH'),
        impersonate_email=os.getenv('GOOGLE_IMPERSONATE_EMAIL')
    )

    # Database session
    session_mgr = SessionManager()

    logger.info("‚úÖ All components initialized")

    # Get recording details
    recording_id = Path(recording_file).stem
    logger.info(f"\n2. Processing recording ID: {recording_id}")

    # Check file size
    file_size = os.path.getsize(recording_file)
    logger.info(f"   File size: {file_size:,} bytes")

    # Create temporary upload URL (in production this would be S3 or similar)
    # For testing, we'll use the local file path
    audio_url = f"file://{recording_file}"

    logger.info("\n3. Starting transcription with Salad Cloud...")
    logger.info("   Features enabled:")
    logger.info("   - Full engine (highest quality)")
    logger.info("   - Word-level timestamps")
    logger.info("   - Sentence-level timestamps")
    logger.info("   - Speaker diarization")
    logger.info("   - Summarization (10 sentences)")
    logger.info("   - Custom vocabulary")
    logger.info("   - SRT format generation")

    # Transcribe with all features
    try:
        result = transcriber.transcribe(
            audio_url=audio_url,
            output_path=None,  # We'll handle saving ourselves
            metadata={
                'recording_id': recording_id,
                'source': 'ringcentral',
                'test_run': True,
                'test_timestamp': datetime.now().isoformat()
            }
        )

        logger.info("\n‚úÖ Transcription completed successfully!")

        # Display results
        logger.info("\n4. Transcription Results:")
        logger.info(f"   - Job ID: {result.job_id}")
        logger.info(f"   - Language: {result.language} (confidence: {result.language_probability:.2%})")
        logger.info(f"   - Word count: {result.word_count}")
        logger.info(f"   - Duration: {result.duration_seconds:.1f} seconds")
        logger.info(f"   - Processing time: {result.processing_time_seconds:.1f} seconds")
        logger.info(f"   - Confidence: {result.confidence:.2%}")
        logger.info(f"   - Segments: {len(result.segments)}")

        # Check for enhanced features
        logger.info("\n5. Enhanced Features Check:")

        # Check segments for word timestamps
        has_word_timestamps = any(
            'words' in seg for seg in result.segments[:5] if seg
        )
        logger.info(f"   - Word timestamps: {'‚úÖ Present' if has_word_timestamps else '‚ùå Missing'}")

        # Check for speaker diarization
        has_speakers = any(
            'speaker' in seg for seg in result.segments[:5] if seg
        )
        logger.info(f"   - Speaker diarization: {'‚úÖ Present' if has_speakers else '‚ùå Missing'}")

        # Check for summary in metadata
        has_summary = 'summary' in result.metadata or 'summarization' in result.metadata
        logger.info(f"   - Summarization: {'‚úÖ Present' if has_summary else '‚ùå Missing'}")

        # Display sample transcript
        logger.info("\n6. Sample Transcript (first 500 chars):")
        logger.info(f"   {result.text[:500]}...")

        # Display first few segments with details
        logger.info("\n7. Sample Segments (first 3):")
        for i, seg in enumerate(result.segments[:3], 1):
            logger.info(f"\n   Segment {i}:")
            logger.info(f"     Text: {seg.get('text', 'N/A')[:100]}...")
            logger.info(f"     Start: {seg.get('start', 'N/A')}s")
            logger.info(f"     End: {seg.get('end', 'N/A')}s")
            if 'speaker' in seg:
                logger.info(f"     Speaker: {seg['speaker']}")
            if 'words' in seg and seg['words']:
                logger.info(f"     Words: {len(seg['words'])} words with timestamps")

        # Save to organized structure
        logger.info("\n8. Organizing data structure...")
        organized_data = organizer.organize_transcription(
            recording_id=recording_id,
            transcription=result.text,
            metadata={
                **result.to_dict(),
                'file_size_bytes': file_size,
                'audio_file': recording_file
            }
        )

        # Save locally for inspection
        test_output_dir = Path('/var/www/call-recording-system/test_output')
        test_output_dir.mkdir(exist_ok=True)

        output_file = test_output_dir / f"{recording_id}_complete.json"
        with open(output_file, 'w') as f:
            json.dump(organized_data, f, indent=2, default=str)

        logger.info(f"   ‚úÖ Saved organized data to {output_file}")

        # Test Google Drive upload
        logger.info("\n9. Testing Google Drive upload...")

        try:
            # Prepare upload data
            upload_data = {
                'recording_id': recording_id,
                'transcription': result.text,
                'metadata': result.to_dict(),
                'organized_data': organized_data
            }

            # Upload to Google Drive
            file_id = drive_manager.upload_json(
                data=upload_data,
                file_name=f"{recording_id}_transcription.json",
                folder_name=f"transcriptions/{datetime.now().strftime('%Y-%m')}"
            )

            logger.info(f"   ‚úÖ Uploaded to Google Drive: {file_id}")

            # Get shareable link
            share_link = drive_manager.get_shareable_link(file_id)
            logger.info(f"   üìé Shareable link: {share_link}")

        except Exception as e:
            logger.error(f"   ‚ùå Google Drive upload failed: {e}")

        # Update database (optional)
        logger.info("\n10. Updating database...")
        try:
            with session_mgr.get_session() as session:
                # Check if recording exists
                recording = session.query(CallRecording).filter_by(
                    recording_id=recording_id
                ).first()

                if recording:
                    recording.transcription_text = result.text
                    recording.transcription_status = 'completed'
                    recording.transcription_metadata = result.to_dict()
                    recording.updated_at = datetime.utcnow()
                    session.commit()
                    logger.info("   ‚úÖ Database updated")
                else:
                    logger.info("   ‚ÑπÔ∏è Recording not in database (test recording)")
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Database update skipped: {e}")

        # Display metrics
        if transcriber.enable_monitoring:
            metrics = transcriber.get_metrics()
            logger.info("\n11. Transcription Metrics:")
            logger.info(f"   - Total jobs: {metrics['total_jobs']}")
            logger.info(f"   - Success rate: {metrics['success_rate']}%")
            logger.info(f"   - Total audio hours: {metrics['total_audio_hours']}")
            logger.info(f"   - Average processing time: {metrics['average_processing_seconds']}s")

        return True

    except Exception as e:
        logger.error(f"\n‚ùå Transcription failed: {e}")
        logger.error(f"   Error type: {type(e).__name__}")
        import traceback
        logger.error(f"   Stack trace:\n{traceback.format_exc()}")
        return False


def main():
    """Main test function"""
    logger.info("=" * 80)
    logger.info("SALAD CLOUD COMPREHENSIVE TRANSCRIPTION TEST")
    logger.info("=" * 80)

    # Get a sample recording from the queue
    audio_dir = Path('/var/www/call-recording-system/data/audio_queue')

    # Find a medium-sized recording (between 500KB and 2MB for quick testing)
    test_files = []
    for mp3_file in audio_dir.glob('*.mp3'):
        size = mp3_file.stat().st_size
        if 500_000 < size < 2_000_000:  # 500KB to 2MB
            test_files.append(mp3_file)

    if not test_files:
        logger.error("No suitable test files found in audio queue")
        return

    # Test with the first suitable file
    test_file = test_files[0]
    logger.info(f"\nSelected test file: {test_file.name}")
    logger.info(f"Size: {test_file.stat().st_size:,} bytes")

    # Run the test
    success = test_single_recording(str(test_file))

    if success:
        logger.info("\n" + "=" * 80)
        logger.info("‚úÖ ALL TESTS PASSED SUCCESSFULLY!")
        logger.info("=" * 80)
        logger.info("\nKey findings:")
        logger.info("- Salad transcription is working")
        logger.info("- All enhanced features are available")
        logger.info("- Google Drive upload is functional")
        logger.info("- Data organization is complete")
        logger.info("\nReady for production transcription!")
    else:
        logger.error("\n" + "=" * 80)
        logger.error("‚ùå TESTS FAILED - REVIEW ERRORS ABOVE")
        logger.error("=" * 80)


if __name__ == "__main__":
    main()