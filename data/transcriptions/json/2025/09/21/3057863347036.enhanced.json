{
  "recording_id": "3057863347036",
  "version": "2.0",
  "timestamp": "2025-09-21T23:06:54.919858Z",
  "call_metadata": {
    "date": "2025-09-21",
    "time": "23:06:54",
    "duration_seconds": 0,
    "direction": "unknown",
    "from": {
      "number": "unknown",
      "name": "",
      "extension": "",
      "department": ""
    },
    "to": {
      "number": "unknown",
      "name": "",
      "company": ""
    },
    "file_size_bytes": 0
  },
  "transcription": {
    "text": " Thank you for calling me from technology. This is Garrett. How may I help you? Hey, Garrett. This is Sean Reeves calling from Corrigo Consulting. And I've got a question for you. I have figured out how to do something kind of cool. I have taught myself how to â€“ it's been a long time since I've had it, but I am scraping my potential client company websites using Python and Beautiful Soup, and I've built some libraries that will allow me to scrape the visible text out. What I did is I created a roll-up with every single one of my companies and their URLs, and I exported it as a CSV. I'm in the process of scraping them all right now to get the text. And I'm going to monkey around with the dog's going to start barking. My wife just got home. I want to re-import all of that information after I clean it up back into those companies. but I don't want to create like 900 duplicate companies. Is there a way or is there something I need to do? Because I think when you upload stuff, I don't think it gives me the right options to avoid creating duplicates. I want it to say, yep, that's the same company. Yep, that's the same address. Yep, that's the same URL. Just load the new data to the appropriate predefined and custom fields or the notes section. Do you follow what I'm saying? Yeah, so our import process does have duplicate checking. So you would need to select from the options in your, so it'll just reference a column in your CSV file against data that's already in the database. and if it does find a match based on that criteria you've selected, it won't create a duplicate. It'll update all the fields that you've mapped in the inputting process. Okay. So in the radial boxes, it's like if you find a duplicate, this is what I want you to do. Just go ahead and make sure the radial boxes are checked, that just update the fields that don't contain any data or overwrite the fields that have data with this new data. I just have to make sure I toggle the right thing. Yeah, that one's called, yeah, it's called update. And so, yeah, it would update. And then you do choose the criteria that PCR uses to decide if it is a match. And for that, it gives you some, you know, predefined options. I don't remember what they are for company. I could actually pull up my database really quick and take a look. Because I don't want to end up with, because that would take me, And I'm sure that there's a super secret squirrel way to, like, if you just added, doubled your database, a way to do like a mass database cleanup where I could delete them all. I just don't want to screw something up. This is actually pretty cool that I figured out, I mean, how to do this. I've been trying to figure out a way to basically get chat GPT rather than me looking at every single website of every single company. I wrote a bunch of elaborate Boolean expressions that capture whether I'm in construction. So are they a general contractor? Are they design build? Are they design bid build? Are they pre-construction planning? Are they a prime contractor? All that kind of stuff. It will review the text. ChatGPT won't scrape, but it can at blistering speed. If you give it the text, especially when you clean up all the HTML tags and garbage, it can read through text in a CSV lickety-split and return values that I tell it. And then I can upload those and code all of my predefined and custom fields so that I don't have to look at all these websites and determine, like, what services do they offer? What type of construction are they doing? You know what I'm saying? I just, like, populated my database and let ChatGPT do it. Yeah, that is cool. That would be awesome. It's a frightening world we live in. Yeah. So I did just start an import on my end for a company import specifically. Were you doing a company import or a name import? Company import. Company, right. Okay. So your duplicate checking criteria options are it has to have a matching company name, website, and city. or it could be just company name and website or it can be company name and city. So that would mean that you have to have that data already in the database on those records to identify it as a duplicate and it would have to match what is on your CSV file. Well, I think that I'll do company and website because that's all I'm exporting is company and website. So I know that if I pulled it out that way, I'll put it back in that way. And then what I can do, then the options when I click on next, I want to make sure that I select which radio buttons to make sure this works correctly. Yeah, and those are the radio buttons. So the first one is how do you want to do your duplicate checking? You'll say update if duplicate is found. And then the other set of radio buttons is the criteria, and you would say company name, website. Okay, got it. Okay, an update if found. So there's any field that's in that. What I do is I have to make sure that the CSV I'm uploading contains the exact same names exactly as they appear as the custom field or a predefined field. And if I am populating a custom field that has multi-select checkboxes, pipe is the separator, correct? Yeah, the double pipe. Yeah, so it would be the two lines next to each other. Is that called pipe? Yeah, I guess that is pipe. Yeah, you do double pipe? Yeah, two lines double. Okay. Yep. Okay, yeah, because that's what it'll be, because I've got fields that are like, okay, we do residential, we do industrial, we do commercial, we do, and I, so it's like that field will have all of them in there, and I want it to check all those boxes, so I have to put it in as like residential double bar or double pipe. Yeah, whatever. Yeah, okay. So I just need to set it up to do that correctly. All right. I think I got it. All right, I'll let you know how it turns out. Yeah, if any other questions come up, let us know. And do you have, there is like a video in our learning center for data import. You could use that as reference too. Do you have access? I'm sure I, why don't you send me the, but why don't you send it to my email, that specific video or the link to that. I know I have it, but if you've got a second, just flip it my way. I went to go searching for it. Sure. Let me, let's see, sreeves at coregolc.com. Is that the best? You got it. Yep, that's it. All right. I will send that your way as well as an article on data import, just in case you want to use that as a reference. Awesome. Thank you very much. I appreciate it. No problem. All right. Catch you guys later. Anything else? Bye. Will do.",
    "confidence": 0.95,
    "language": "en-US",
    "language_probability": 1.0,
    "word_count": 0,
    "duration_seconds": 0,
    "processing_time_seconds": 1695.419221,
    "salad_processing_time": 28.327977657318115,
    "overall_processing_time": 1695.419221,
    "segments": [],
    "word_segments": [],
    "speakers": [],
    "srt_content": "",
    "summary": " Thank you for calling me from technology.  This is Garrett.  How may I help you? Hey, Garrett.",
    "job_id": "838e8ec4-b0bb-4e41-bb8c-bb0d5e7da3cd",
    "timestamps": []
  },
  "ai_analysis": {
    "summary": " Thank you for calling me from technology.  This is Garrett.  How may I help you? Hey, Garrett.",
    "sentiment": {
      "overall": "neutral",
      "customer": "neutral",
      "agent": "professional",
      "score": 0.5
    },
    "topics": [],
    "entities": [],
    "action_items": [],
    "customer_satisfaction": {
      "predicted_score": 3,
      "indicators": [
        "neutral_interaction"
      ]
    },
    "key_moments": [],
    "conversation_flow": {
      "speaker_changes": 0,
      "total_segments": 0,
      "agent_speaking_percentage": 0,
      "customer_speaking_percentage": 0,
      "average_turn_duration": 0,
      "conversation_pace": "slow"
    }
  },
  "support_metrics": {
    "issue_type": "general",
    "resolution_status": "pending",
    "first_call_resolution": false,
    "escalation_required": false,
    "follow_up_needed": false,
    "agent_performance": {
      "greeting": true,
      "empathy_shown": false,
      "solution_offered": true,
      "proper_closing": true
    }
  },
  "n8n_metadata": {
    "workflow_ready": true,
    "processing_queue": "support_calls",
    "tags": [],
    "webhook_url": "",
    "automation_triggers": []
  },
  "storage": {
    "google_drive_id": "",
    "google_drive_url": "",
    "local_path": "/data/transcriptions/json/2025/09/21/3057863347036.json",
    "backup_status": "pending",
    "retention_days": 90
  },
  "embeddings": {
    "text_embedding": null,
    "summary_embedding": null,
    "model": "text-embedding-ada-002"
  },
  "classifications": {
    "intent": null,
    "urgency": null,
    "category": null,
    "subcategory": null
  },
  "ml_metadata": {
    "suitable_for_training": true,
    "quality_score": 0.95,
    "has_ground_truth": false,
    "annotations": []
  }
}